<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Hierarchical Cluster Analysis in RAISINS</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="Clustertutorial_files/libs/clipboard/clipboard.min.js"></script>
<script src="Clustertutorial_files/libs/quarto-html/quarto.js"></script>
<script src="Clustertutorial_files/libs/quarto-html/popper.min.js"></script>
<script src="Clustertutorial_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="Clustertutorial_files/libs/quarto-html/anchor.min.js"></script>
<link href="Clustertutorial_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="Clustertutorial_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="Clustertutorial_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="Clustertutorial_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="Clustertutorial_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">


<link rel="stylesheet" href="custom.css">
</head>

<body>

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#how-to-prepare-your-data" id="toc-how-to-prepare-your-data" class="nav-link active" data-scroll-target="#how-to-prepare-your-data">How to Prepare Your Data?</a>
  <ul class="collapse">
  <li><a href="#preparing-data-in-ms-excel" id="toc-preparing-data-in-ms-excel" class="nav-link" data-scroll-target="#preparing-data-in-ms-excel">Preparing data in MS Excel</a>
  <ul class="collapse">
  <li><a href="#creating-a-data-file-in-ms-excel" id="toc-creating-a-data-file-in-ms-excel" class="nav-link" data-scroll-target="#creating-a-data-file-in-ms-excel">1. Creating a Data File in MS Excel</a></li>
  <li><a href="#file-format-recommendation" id="toc-file-format-recommendation" class="nav-link" data-scroll-target="#file-format-recommendation">2. File Format Recommendation</a></li>
  <li><a href="#naming-columns-and-treatments" id="toc-naming-columns-and-treatments" class="nav-link" data-scroll-target="#naming-columns-and-treatments">3. Naming Columns and Treatments</a></li>
  <li><a href="#creating-data-using-the-app-recommended-method" id="toc-creating-data-using-the-app-recommended-method" class="nav-link" data-scroll-target="#creating-data-using-the-app-recommended-method">4. Creating Data Using the App (Recommended Method)</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#how-to-upload-the-data-file-for-analysis" id="toc-how-to-upload-the-data-file-for-analysis" class="nav-link" data-scroll-target="#how-to-upload-the-data-file-for-analysis">How to upload the data file for analysis ?</a></li>
  <li><a href="#different-plot-types-and-additional-options" id="toc-different-plot-types-and-additional-options" class="nav-link" data-scroll-target="#different-plot-types-and-additional-options">Different plot types and additional options</a></li>
  <li><a href="#heatmap-in-raisins" id="toc-heatmap-in-raisins" class="nav-link" data-scroll-target="#heatmap-in-raisins">Heatmap in RAISINS</a></li>
  <li><a href="#the-four-important-statistical-components-available-in-raisins" id="toc-the-four-important-statistical-components-available-in-raisins" class="nav-link" data-scroll-target="#the-four-important-statistical-components-available-in-raisins">The four important statistical components available in RAISINS</a></li>
  <li><a href="#hcpc-hierarchical-clustering-on-principal-components" id="toc-hcpc-hierarchical-clustering-on-principal-components" class="nav-link" data-scroll-target="#hcpc-hierarchical-clustering-on-principal-components">HCPC (Hierarchical Clustering on Principal Components)</a></li>
  </ul>
</nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Hierarchical Cluster Analysis in RAISINS</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<style>
  sup {
    color: blue;
    font-size: 0.8em;  /* smaller superscript */
  }
  .affiliations {
    color: grey;
    font-size: 0.9em;  /* one size smaller than normal */
    margin-top: 0.2em;
  }
</style>
<p>‚Äî‚Äî‚Äî‚Äî‚Äî<sup>1</sup>, Dr Pratheesh P Gopinath<sup>2</sup></p>
<div class="affiliations">
<p><sup>1</sup>Statoberry LLP, <sup>2</sup>Department of Agricultural Statistics, Kerala Agricultural University,</p>
</div>
<p>Hierarchical Cluster Analysis (HCA) is a statistical method used to group similar data points into clusters based on their characteristics, building a tree-like structure to show how these groups form. In RAISINS (R and AI Solutions for INferential Statistics), a web-based platform for statistical analysis, HCA is available in the <code>Analysis module</code>. It‚Äôs particularly useful in agricultural research for categorizing genotypes, treatments, or traits by minimizing within-cluster distances and maximizing between-cluster differences. The process starts with individual data points and merges them iteratively into larger clusters, visualized through dendrograms.</p>
<p><em>Below is a compact, practical guide you can use as a tutorial to perform Hierarchical Cluster Analysis in RAISINS.</em></p>
<section id="how-to-prepare-your-data" class="level1">
<h1>How to Prepare Your Data?</h1>
<p>Proper data preparation is crucial for accurate HCA results in RAISINS. The platform guides users through preprocessing, but following best practices ensures reliability. What truly matters is the quality of your data! As the saying goes, ‚Äúgarbage in, garbage out‚Äù - and this holds true for any software.</p>
<p><em>To prepare your dataset for analysis in RAISINS, you have two options</em>:</p>
<ol type="1">
<li>Create your dataset in MS Excel</li>
<li>Build your dataset directly within the RAISINS app</li>
</ol>
<section id="preparing-data-in-ms-excel" class="level2">
<h2 class="anchored" data-anchor-id="preparing-data-in-ms-excel">Preparing data in MS Excel</h2>
<p>RAISINS allows for analyzing multiple characters simultaneously. So you can enter the observations for all characters for a particular set of treatments in a single excel file.</p>
<section id="creating-a-data-file-in-ms-excel" class="level3">
<h3 class="anchored" data-anchor-id="creating-a-data-file-in-ms-excel">1. Creating a Data File in MS Excel</h3>
<ul>
<li><p>Open a new microsoft excel file, use single sheet only.</p></li>
<li><p>Start with Cell A1: Open a new MS Excel file and begin entering data from cell A1. Do not leave any blank rows above.</p></li>
<li><p>First Row - Column Names: The first row must contain the column names.</p></li>
<li><p>Column 1: Enter treatment/labels. <strong>There should not be any repetition in the label ID‚Äôs</strong>. If there is replications, you can use the mean values.</p></li>
<li><p>From Column 2 Onwards: Enter the names of each character(variable) under study as separate columns (e.g.Murder, Assault, UrbanPop, Rape). You can give any names to the columns.</p></li>
</ul>
<p>See <a href="#fig-modata1">Figure&nbsp;1</a> showing how the prepared Excel file for upload should look like</p>
<div id="fig-modata1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="PREP1.webp" class="img-fluid figure-img" style="width:45.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;1: Model1 showing how the prepared Excel file for upload should look like</figcaption>
</figure>
</div>
</section>
<section id="file-format-recommendation" class="level3">
<h3 class="anchored" data-anchor-id="file-format-recommendation">2. File Format Recommendation</h3>
<ul>
<li>In RAISINS you can upload file in xls, xlsx or csv format. But we recommend a csv format as it will be much lighter.</li>
</ul>
<details>
<summary>
Follow the below steps save your Excel file in csv format.
</summary>
<ol type="1">
<li><p>Open your Excel file.</p></li>
<li><p>Click on <strong>File</strong> in the top-left corner.</p></li>
<li><p>Select <code>Save As</code> from the menu.</p></li>
<li><p>Choose the <strong>location</strong> where you want to save the file.</p></li>
<li><p>In the Save as type <strong>dropdown menu</strong>, select <code>CSV (Comma delimited) (*.csv)</code>.</p></li>
<li><p>Enter a <strong>name</strong> for your file.</p></li>
<li><p>Click <strong>Save</strong>.</p></li>
</ol>
</details></section>
<section id="naming-columns-and-treatments" class="level3">
<h3 class="anchored" data-anchor-id="naming-columns-and-treatments">3. Naming Columns and Treatments</h3>
<ul>
<li><p>Keep It Simple and Straight (KISS): Use simple and short names for column headers.</p></li>
<li><p>Avoid Complexity: Do not include units, special characters, or spaces in names (e.g., use char1 instead of Character 1). This helps ensure the names appear neatly in plots and outputs.</p></li>
<li><p>This helps ensure the names appear neatly in plots and outputs.</p></li>
</ul>
<details>
<summary>
Dataset Creation Rules
</summary>
<ol type="1">
<li><strong>Column Naming Convention</strong>
<ul>
<li>No spaces allowed in column names.<br>
</li>
<li>Use underscores (<code>_</code>) or full stops (<code>.</code>) for separation.</li>
<li>Avoid symbols and special characters like %,# etc</li>
</ul></li>
<li><strong>Data Arrangement</strong>
<ul>
<li>Start data arrangement towards the upper-left corner.<br>
</li>
<li>Ensure the row above the data is not blank.</li>
</ul></li>
<li><strong>Cell Management</strong>
<ul>
<li>Avoid typing or deleting in cells without data.<br>
</li>
<li>If needed, select affected cells, right-click, and select <strong>Clear Contents</strong>.</li>
</ul></li>
<li><strong>Column Relevance</strong>
<ul>
<li>Name all columns meaningfully.<br>
</li>
<li>Exclude unnecessary columns not required for analysis.</li>
</ul></li>
</ol>
</details>
</section>
<section id="creating-data-using-the-app-recommended-method" class="level3">
<h3 class="anchored" data-anchor-id="creating-data-using-the-app-recommended-method">4. Creating Data Using the App (Recommended Method)</h3>
<ul>
<li><p>Navigate to <code>Create Data</code> Tab: Click on the Create Dataset tab in the main menu at the top of the app.</p></li>
<li><p>Specify Details: Enter the levels of Factor A, Factor B, Factor C and number of characters under study in the window that opens.</p></li>
<li><p>Then click <code>create</code></p></li>
<li><p>Model Data Entry File: A template for data entry will be generated. You can:</p>
<ul>
<li><p>Directly enter your data into this template.</p></li>
<li><p>Or, copy-paste data from an existing Excel file.</p></li>
</ul></li>
<li><p>Download as CSV: Once the data is entered, click on the <code>Download CSV</code> File button. The downloaded CSV file can be uploaded for analysis in <code>Analysis tab</code>.</p></li>
</ul>
</section>
</section>
</section>
<section id="how-to-upload-the-data-file-for-analysis" class="level1">
<h1>How to upload the data file for analysis ?</h1>
<ul>
<li><p>Upload the Prepared CSV/XLS File: Go to the <code>Analysis tab</code>(See <a href="#fig-modata2">Figure&nbsp;2</a>) and upload your prepared data file.</p></li>
<li><p>Ensure Clean Data: Keep the file focused on the data; avoid adding any extra information or notes outside the data area.</p></li>
</ul>
<p><em>By following these instructions, you will have a well-prepared data file ready for analysis, allowing you to process multiple characters together</em></p>
<div id="fig-modata2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="tab1analysis1.webp" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;2: Analysis tab</figcaption>
</figure>
</div>
</section>
<section id="different-plot-types-and-additional-options" class="level1">
<h1>Different plot types and additional options</h1>
<p>A dendrogram is a tree-like diagram that visually represents how hierarchical clustering groups data step by step, allowing you to explore relationships and cluster formation within a dataset. A dendrogram displays the process of merging (or sometimes splitting) clusters during hierarchical cluster analysis.</p>
<details>
<summary>
Step-by-Step: How to read a Dendrogram ?
</summary>
<ol type="1">
<li><p><strong>Start at the bottom</strong> - Each leaf represents a single observation or sample.</p></li>
<li><p><strong>Follow the lines upward</strong> - The first merges connect the most similar items. These connections indicate that the points or small clusters joined are very close based on the chosen similarity measure.</p></li>
<li><p><strong>Merging clusters</strong> - As you go higher, clusters are combined with others, and each branching indicates additional clustering - think of it as building a family tree for your data.</p></li>
<li><p><strong>Branch heights</strong> - The height at which branches merge tells you how similar the merged groups are-the lower the connection, the more similar the groups.</p></li>
<li><p><strong>Deciding number of clusters</strong> - By ‚Äúcutting‚Äù the tree horizontally at a given level (distance threshold), you divide the data into clusters-each branch below the cut line forms a cluster.</p></li>
</ol>
</details>
<p>RAISINS is designed for a smooth and hassle-free experience. Once you click the <code>Run Analysis</code> button, all relevant results and outputs appear instantly-leaving no room for confusion. We‚Äôve ensured that every possible dendrogram related to the Hierarchical Cluster analysis is readily available. Color-Coded Clusters dendrogram performed with the complete linkage method and euclidean distance metric, identified through elbow method, resulting in 2 clusters is available by default and each dendrogram comes with a gear icon at the top-left corner, allowing you to customize its appearance. You can also download these plots in high-quality PNG (300 dpi), TIFF or PDF formats for use in reports or presentations.</p>
<p>Explore <a href="#fig-1">Figure&nbsp;3</a>, <a href="#fig-2">Figure&nbsp;4</a>, <a href="#fig-3">Figure&nbsp;5</a>, <a href="#fig-4">Figure&nbsp;6</a>, <a href="#fig-5">Figure&nbsp;7</a>, <a href="#fig-6">Figure&nbsp;8</a>, <a href="#fig-7">Figure&nbsp;9</a>, <a href="#fig-8">Figure&nbsp;10</a> where each dendrogram available in RAISINS is <strong>visually illustrated and accompanied by a clear, insightful description below</strong>, helping you easily understand the structure and meaning of each clustering pattern.</p>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ColorCoded_Clusters.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;3: <strong>Color coded clusters (k = 2)</strong><br>
A color-coded cluster dendrogram is an enhanced version of the basic dendrogram where branches or clusters are colored differently to clearly distinguish the groupings formed by hierarchical clustering. This makes interpreting the tree much easier, especially for large datasets or when clusters overlap visually.</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Vertical_Dendrogram.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;4: <strong>Vertical Dendrogram (k = 2)</strong><br>
A vertical dendrogram is a classic, user-friendly way to display hierarchical clustering results with the data points along the bottom and cluster merges represented by upward vertical lines, enabling easy interpretation of cluster hierarchy and distances.</figcaption>
</figure>
</div>
</div>
</div>
</div>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Horizontal_Dendrogram.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;5: <strong>Horizontal Dendrogram (k = 2)</strong><br>
A horizontal dendrogram is a tree-like diagram used to visualize hierarchical clustering results where the structure extends horizontally rather than vertically. In this layout, the individual observations or samples appear along the vertical axis, and the branches stretch left to right, representing how clusters merge step-by-step based on dissimilarity or distance.</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-4" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Ward's_Linkage.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;6: <strong>Ward‚Äôs Linkage (k = 2)</strong><br>
Ward‚Äôs linkage is a hierarchical clustering method focused on minimizing the increase in total within-cluster variance (or error sum of squares) when merging clusters. It is widely used because it tends to produce compact, spherical clusters, making it popular in many applications like biological data, market segmentation, and more.</figcaption>
</figure>
</div>
</div>
</div>
</div>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-5" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Rectangular_Clusters.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;7: <strong>Rectangular Clusters (k = 2)</strong><br>
Rectangular clusters are simply the visual aids drawn as boxes around groups of points identified as clusters on dendrograms or heat maps to facilitate clear, intuitive interpretation of cluster structure in hierarchical clustering outputs.</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-6" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Circular_dendrogram.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;8: <strong>Circular dendrogram (k = 2)</strong><br>
A Circular Dendrogram is a radial, space-efficient alternative to the classical dendrogram, arranging hierarchical cluster branches in concentric circles around a center. It enhances visual clarity for large or complex datasets by providing a 360-degree view of similarity and cluster structures, making it a valuable tool for hierarchical data visualization.</figcaption>
</figure>
</div>
</div>
</div>
</div>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-7" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Rectangular_Clusters.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;9: <strong>Colored Rectangular Dendrogram (k = 2)</strong><br>
A coloured rectangular dendrogram is an enhanced dendrogram visualization where clusters are not only enclosed in rectangular boxes but these boxes and the associated branches are also color-coded to clearly distinguish different clusters. This combination improves interpretability and presentation of hierarchical clustering. results.</figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-8" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Rectangular_Clusters.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;10: <strong>Classical Dendrogram (k = 2)</strong> A classical dendrogram is the traditional tree-like diagram used in hierarchical cluster analysis to represent the nested grouping of objects based on their similarity or distance. It is a fundamental visualization tool that shows how clusters are formed progressively, starting from each individual object and merging step by step into larger clusters until all objects are grouped into one.<br>
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<p><em>In addition to the various plot types available in RAISINS, the platform also provides several customization options to refine your clustering analysis</em>.</p>
<p>You can explore and adjust the following settings:</p>
<ul>
<li>Linkage Methods available in RAISINS - single, complete, average, ward.D2, mcquitty, median and centroid.</li>
</ul>
<details>
<summary>
Lets understand the different linkage methods
</summary>
<div class="callout callout-style-default callout-note callout-titled" title="üîπ Single linkage">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
üîπ Single linkage
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Single linkage defines the distance between two clusters as the minimum distance between any pair of points, one from each cluster. This approach often produces elongated, chain-like clusters because it merges clusters based on the closest individual pair of points. It is sensitive to noise and outliers, as a single close pair can link otherwise distant clusters.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="üîπ Complete linkage">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
üîπ Complete linkage
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Complete linkage measures the distance between two clusters as the maximum distance between any point in one cluster and any point in the other cluster. This method tends to produce more compact and spherical clusters by enforcing that all members within a cluster are close to each other. It is less sensitive to outliers compared to single linkage.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="üîπ Average linkage">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
üîπ Average linkage
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Average linkage computes the clustering distance as the average of all pairwise distances between members of the two clusters. It balances the tendency of single and complete linkage, typically yielding clusters that are more balanced in shape and size by considering all members evenly.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="üîπ Ward.D2 Linkage">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
üîπ Ward.D2 Linkage
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Ward‚Äôs linkage merges clusters such that the increase in total within-cluster variance is minimized. It uses a variance-minimizing criterion based on squared Euclidean distances and tends to produce compact, spherical clusters. Ward.D2 specifically refers to Ward‚Äôs method with squared distances, popular for its stable and interpretable clusters.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="üîπ McQuitty Linkage">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
üîπ McQuitty Linkage
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>This method uses a simple average of distances weighted by cluster sizes when merging clusters. It‚Äôs a variant of average linkage and provides a compromise that accounts for different cluster sizes during the merge.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="üîπ Median Linkage">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
üîπ Median Linkage
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Median linkage calculates the distance between clusters based on the median of the points within each cluster (cluster median) rather than the mean. This method can be more robust to skewed data distributions but may result in non-monotonic clustering (reversals) in dendrograms.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="üîπ Centroid Linkage">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
üîπ Centroid Linkage
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Centroid linkage computes the distance between two clusters as the Euclidean distance between their centroids (mean vectors). It effectively merges clusters based on the center of mass but may produce inversions (discontinuities) in the dendrogram if the merging decreases cluster distances temporarily..</p>
</div>
</div>
</div>
</details>
<ul>
<li>Distance Metrics available in RAISINS: Euclidean, Manhattan, Maximum, Canberra, Minkowski.</li>
</ul>
<details>
<summary>
Lets understand the different Distance Metrics
</summary>
<div class="callout callout-style-default callout-note callout-titled" title="üîπ Euclidean Distance">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
üîπ Euclidean Distance
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Euclidean distance is the most familiar form of distance measurement, representing the straight-line distance between two points in Euclidean space. It is calculated using the Pythagorean theorem, where the distance between two points is the square root of the sum of the squared differences across all dimensions. For example, in a two-dimensional space, the distance between points (x‚ÇÅ, y‚ÇÅ) and (x‚ÇÇ, y‚ÇÇ) is given by the formula ‚àö((x‚ÇÇ ‚àí x‚ÇÅ)¬≤ + (y‚ÇÇ ‚àí y‚ÇÅ)¬≤). This metric measures the shortest path between points, like stretching a string tight between two points on a map, making it widely used in machine learning, such as clustering and classification algorithms.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="üîπ Manhattan Distance">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
üîπ Manhattan Distance
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Manhattan distance, also known as city block distance, sums the absolute differences of the coordinates between two points in a grid-like path. Unlike Euclidean distance, which measures the shortest ‚Äúas-the-crow-flies‚Äù route, Manhattan distance measures how far apart two points are if you can only move along grid lines‚Äîlike navigating city streets laid out in a grid pattern. For example, the distance between (x‚ÇÅ, y‚ÇÅ) and (x‚ÇÇ, y‚ÇÇ) is |x‚ÇÇ ‚àí x‚ÇÅ| + |y‚ÇÇ ‚àí y‚ÇÅ|, often used in urban planning and in applications where movement is restricted to axes-aligned paths.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="üîπ Maximum Distance">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
üîπ Maximum Distance
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Maximum distance, also known as Chebyshev distance, considers the greatest absolute difference among all coordinate pairs between two points. It effectively measures how far apart two points are in terms of the most significant coordinate difference. Mathematically, for points (x‚ÇÅ, y‚ÇÅ) and (x‚ÇÇ, y‚ÇÇ), it is max(|x‚ÇÇ ‚àí x‚ÇÅ|, |y‚ÇÇ ‚àí y‚ÇÅ|). This metric is useful in chess (king‚Äôs move), robotics (max step size), and in certain clustering methods, where the largest coordinate gap dominates the distance calculation.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="üîπ Canberra Distance">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-11-contents" aria-controls="callout-11" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
üîπ Canberra Distance
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-11" class="callout-11-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Canberra distance is a weighted version of difference measurement that emphasizes smaller differences, especially when values are close to zero. It is calculated as the sum of the ratios |x‚ÇÇ ‚àí x‚ÇÅ| / (|x‚ÇÇ| + |x‚ÇÅ|) across all dimensions. Because it gives more weight to differences when values are small, it is effective for datasets with many small or sparse values, often used in bioinformatics, economics, and fields dealing with relative differences.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="üîπ Minkowski Distance">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
üîπ Minkowski Distance
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Minkowski distance is a generalization of Euclidean and Manhattan distances, characterized by a parameter p, called the order. When p=1, Minkowski becomes Manhattan distance; when p=2, it becomes Euclidean distance. For other values of p, it defines a different form of distance calculation, where higher p emphasizes larger differences more heavily, and lower p emphasizes smaller differences. The formula involves taking the p-th root of the sum of the absolute differences raised to the power p across all dimensions, making it very flexible for various applications.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="üîπ Median and Centroid">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-13-contents" aria-controls="callout-13" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
üîπ Median and Centroid
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-13" class="callout-13-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Median distance refers to the measure of the difference between data points based on their median values; it is more robust to outliers in skewed data distributions. Centroid distance specifically considers the Euclidean distance between the centroids (mean points) of data clusters. The centroid-based method is widely used in clustering techniques like k-means because it measures the central point of a cluster, making it useful for cluster center-based algorithms but sensitive to outliers, which can shift the centroid.</p>
</div>
</div>
</div>
</details>
<ul>
<li>Optimal k Methods available in RAISINS : Elbow, Silhouette, Gap Statistic</li>
</ul>
<details>
<summary>
Lets understand the different optimal k Methods
</summary>
<div class="callout callout-style-default callout-note callout-titled" title="üîπ  Elbow Method">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-14-contents" aria-controls="callout-14" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
üîπ Elbow Method
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-14" class="callout-14-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>The elbow method is a heuristic used in clustering analysis, particularly with K-means, to determine the optimal number of clusters. It involves plotting the within-cluster sum of squares (WCSS) against different values of k (number of clusters). As the number of clusters increases, WCSS decreases because the data points within each cluster become more tightly grouped. The goal is to identify the ‚Äúelbow‚Äù point in the plot where the rate of decrease sharply changes, indicating an optimal balance between minimizing intra-cluster variance and avoiding overfitting. This point suggests the most appropriate number of clusters, where adding more clusters yields diminishing improvements.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="üîπ  Silhouette Method">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-15-contents" aria-controls="callout-15" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
üîπ Silhouette Method
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-15" class="callout-15-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>The Silhouette method measures how similar an object is to its own cluster compared to other clusters. For each data point, the Silhouette score ranges from -1 to 1, with higher scores indicating better clustering (points are closer to members of their own cluster than to other clusters). The average silhouette score across all points for different cluster numbers helps identify the optimal k: the higher the average score, the better the clustering. This method considers both cohesion within clusters and separation between clusters, providing a more nuanced evaluation of clustering quality than solely looking at variance.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="üîπ  Gap Statistic">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-16-contents" aria-controls="callout-16" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
üîπ Gap Statistic
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-16" class="callout-16-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>The Gap Statistic compares the total within-cluster dispersion for different k values with their expected dispersion under a null reference distribution (usually a uniform distribution of points). It calculates the gap between the observed clustering and the expected clustering under randomness: a larger gap indicates more meaningful, well-separated clusters. The optimal number of clusters is the one where the gap statistic reaches its maximum, suggesting that the clustering structure differs significantly from random noise. This method is robust but more computationally intensive, as it involves generating multiple reference datasets for comparison.</p>
</div>
</div>
</div>
</details>
<ul>
<li>Scaling Options available in raisins: zscore, center, minmax, unitlength, robust, none</li>
</ul>
<details>
<summary>
Lets understand the different scaling options
</summary>
<div class="callout callout-style-default callout-note callout-titled" title="üîπ  zscore">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-17-contents" aria-controls="callout-17" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
üîπ zscore
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-17" class="callout-17-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Z-score normalization, also known as standardization, transforms data so that it has a mean of 0 and a standard deviation of 1. This method computes the Z-score for each data point by subtracting the dataset‚Äôs mean (Œº) and dividing by its standard deviation (œÉ). The resulting scaled data indicates how many standard deviations each point is from the mean. It is particularly useful for datasets with roughly normal distributions and algorithms that assume normality, such as linear regression or SVM, as it removes scale bias and enhances comparability across features.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="üîπ  Center">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-18-contents" aria-controls="callout-18" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
üîπ Center
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-18" class="callout-18-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Centering data refers to subtracting the mean of a feature from each data point, effectively shifting the data so the mean becomes zero without changing the data‚Äôs variance or distribution shape. This operation is fundamental to many data preprocessing steps, such as Z-score normalization, and helps algorithms interpret features more straightforwardly by aligning data around a common point, making the analysis less affected by location shifts.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="üîπ  MinMax">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-19-contents" aria-controls="callout-19" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
üîπ MinMax
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-19" class="callout-19-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Min-Max scaling rescales data to a fixed range, typically. It adjusts each feature by subtracting the minimum value and dividing by the range (max - min), effectively compressing all data within the specified bounds. This technique preserves the original distribution but is highly sensitive to outliers, which can distort the scaled values by expanding the range. Min-Max normalization is often used in neural networks and gradient-based algorithms where feature bounds matter.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="üîπ  Unit Length">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-20-contents" aria-controls="callout-20" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
üîπ Unit Length
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-20" class="callout-20-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Unit length scaling normalizes each data sample (or feature vector) so that its total length (or Euclidean norm) equals 1. This is achieved by dividing each vector by its magnitude, which is the square root of the sum of squared components. It‚Äôs commonly used in text analysis (e.g., TF-IDF vectors) and machine learning algorithms that rely on cosine similarity, as it ensures all vectors are on the same scale, emphasizing direction over magnitude.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled" title="üîπ  Robust">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-21-contents" aria-controls="callout-21" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
üîπ Robust
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-21" class="callout-21-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Robust scaling uses statistics less sensitive to outliers, typically by subtracting the median and dividing by the interquartile range (IQR). This method centers the data around the median and scales it according to the spread of the middle 50% of data points, making it effective when dealing with noisy data or datasets with extreme outliers. Its primary goal is to produce scaled data that reflects the true distribution of the bulk of the data without being skewed by outliers.</p>
</div>
</div>
</div>
</details>
<ul>
<li>Number of Clusters: Specify or adjust the number of clusters to be formed based on your analysis needs.</li>
</ul>
</section>
<section id="heatmap-in-raisins" class="level1">
<h1>Heatmap in RAISINS</h1>
<p>A heatmap in cluster analysis is a visualization technique that represents data values in a matrix format using colors to indicate magnitude, typically after both the rows and columns have been reordered based on hierarchical clustering results. The integration of heatmaps with cluster analysis allows you to visually explore and identify patterns, groupings, or similarities among observations (rows) and variables (columns).</p>
<p>In the RAISINS platform after uploading your data click on the <code>Heatmap tab</code> to generate the heatmap and you can use the gear icon to customize your heatmap (See <a href="#fig-hptab">Figure&nbsp;11</a>) By default the data are standardized using the <code>zscore</code> scaling method, ensuring all features contribute equally to clustering, which was performed using the <code>complete</code> linkage method and <code>euclidean</code> distance metric, resulting in <code>2</code> clusters.You can also download the heatmapin high-quality PNG (300 dpi), TIFF or PDF formats for use in reports or presentations.</p>
<div id="fig-hptab" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Heatmaptab.png" class="img-fluid figure-img" style="width:75.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;11: <strong>How to access the Heatmap tab in RAISINS</strong></figcaption>
</figure>
</div>
<p>See <a href="#fig-hp">Figure&nbsp;12</a> where blocks of similar colors indicate labels or variables with related profiles, and the accompanying dendrograms illustrate their hierarchical relationships, making it easier to identify groups that share similar characteristics or expression patterns.</p>
<div id="fig-hp" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="HMap.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;12: <strong>Heatmap in RAISINS</strong></figcaption>
</figure>
</div>
</section>
<section id="the-four-important-statistical-components-available-in-raisins" class="level1">
<h1>The four important statistical components available in RAISINS</h1>
<p>In the RAISINS platform after uploading your data <code>select the labels</code> then <code>select the clustering variables</code> of your choice, then click on <code>Run Analysis</code> and go to <code>Metrics</code> (See <a href="#fig-adm">Figure&nbsp;13</a>) to generate Distance matrix, Cluster-wise means, Intra-cluster Statistics and Inter-cluster Statistics tables and you can either copy this file or download these tables in <code>.xlsx</code> or <code>.csv</code> formats for use in reports or presentations.</p>
<div id="fig-adm" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="mettab.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;13: <strong>Metrics tab in RAISINS</strong></figcaption>
</figure>
</div>
<p><em>Below given is a brief description on the four statistical components available in RAISINS</em></p>
<ol type="1">
<li>Distance Matrix (euclidean method) - See <a href="#fig-dm">Figure&nbsp;14</a></li>
</ol>
<div id="fig-dm" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Distance_matrix.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;14: <strong>Distance Matrix in RAISINS</strong></figcaption>
</figure>
</div>
<p>In hierarchical clustering, the distance matrix represents the pairwise dissimilarities or distances between all observations in the dataset. It quantifies how similar or different each observation is from every other observation and serves as the foundation for grouping observations into clusters. The distance matrix provides a reference for understanding the relative closeness of observations and guides the formation of clusters based on similarity.</p>
<ol start="2" type="1">
<li>Cluster means - See <a href="#fig-cwm">Figure&nbsp;15</a></li>
</ol>
<div id="fig-cwm" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Cluster_wise_means.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;15: <strong>Cluster wise means in RAISINS</strong></figcaption>
</figure>
</div>
<p>In hierarchical clustering, the cluster mean represents the average values of all variables for the observations within a cluster, summarizing the central tendency of the cluster and providing a reference point to understand the characteristics of the grouped data. It represents the typical characteristics of that cluster.</p>
<ol start="3" type="1">
<li>Intra-cluster Statistics - See <a href="#fig-itra">Figure&nbsp;16</a></li>
</ol>
<div id="fig-itra" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Intracluster_statistics.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;16: <strong>Intracluster statistics</strong></figcaption>
</figure>
</div>
<p>In hierarchical clustering, intra-cluster statistics measure the compactness or similarity of observations within the same cluster. They quantify how closely the members of a cluster resemble each other, often using metrics like the average distance between observations and the cluster mean. These statistics help assess the cohesion of a cluster, indicating how homogeneous or tightly grouped the cluster members are.</p>
<ol start="4" type="1">
<li>Inter-cluster Statistics - See <a href="#fig-iter">Figure&nbsp;17</a></li>
</ol>
<div id="fig-iter" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Intercluster_statistics.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;17: <strong>Intercluster statistics</strong></figcaption>
</figure>
</div>
<p>In hierarchical clustering, inter-cluster statistics measure the separation or dissimilarity between different clusters. They quantify how distinct or far apart the clusters are from each other, often using metrics like the distance between cluster means or centroids. These statistics help assess the distinctness of clusters, indicating how well the clustering algorithm has separated different groups in the dataset.</p>
</section>
<section id="hcpc-hierarchical-clustering-on-principal-components" class="level1">
<h1>HCPC (Hierarchical Clustering on Principal Components)</h1>
<p>Hierarchical clustering on principal components (HCPC) is a hybrid approach that combines the strengths of principal component analysis (PCA) and hierarchical clustering. PCA first reduces the dimensionality of the dataset by summarizing correlated variables into a smaller set of uncorrelated components that retain most of the original variance. Then, hierarchical clustering is performed on these principal components instead of the raw variables, which enhances the separation of clusters and reduces noise caused by variable correlations. This method is particularly useful for visualizing and identifying meaningful groupings in complex multivariate datasets, as it simplifies interpretation while preserving the main structure of the data.</p>
<details>
<summary>
When to use HCPC ?
</summary>
<ul>
<li><p>When you have a large dataset with many continuous variables and want to reduce dimensionality before clustering to improve interpretability and cluster quality.</p></li>
<li><p>When your dataset contains categorical variables, multiple correspondence analysis (MCA) or factor analysis can transform them into continuous principal components suitable for clustering.</p></li>
<li><p>When original variables are correlated or noisy, HCPC clusters on principal components that summarize the main variance structure and filter noise, leading to more meaningful and stable clusters.</p></li>
<li><p>When you want an integrated approach combining principal component analysis for dimensionality reduction, hierarchical clustering for initial cluster identification, and k-means clustering for refinement.</p></li>
<li><p>When exploring multivariate data for identifying natural groupings, patterns, or clusters with clearer separation and visual representation (e.g., factor maps, chord diagrams).</p></li>
<li><p>When the goal is simplifying complex multivariate data for easier interpretation and presentation in reports or scientific communication.</p></li>
</ul>
</details>
<details>
<summary>
Difference between HCPC and classical HCA
</summary>
<ul>
<li><p>HCPC applies Principal Component Analysis (PCA) first to reduce data dimensionality before clustering; HCA clusters directly on the original variables.</p></li>
<li><p>HCPC clusters the uncorrelated principal components that represent the main variance structure, filtering noise and redundancy; HCA uses raw data and can be influenced by correlated variables.</p></li>
<li><p>HCPC integrates PCA, hierarchical clustering, and k-means clustering to improve cluster stability and quality; HCA only involves hierarchical clustering.</p></li>
<li><p>HCPC is designed for complex, high-dimensional, or mixed-type datasets; HCA is suitable for simpler, low-dimensional data.</p></li>
<li><p>HCPC produces enhanced visualizations like factor maps and chord diagrams for better cluster interpretation; HCA mainly produces dendrograms based on distances.</p></li>
<li><p>HCPC requires additional computational steps but offers more robust and interpretable clusters; HCA is simpler and faster but may lead to less meaningful clusters in complex data.</p></li>
</ul>
</details>
<p>In the RAISINS platform after uploading your data <code>select the labels</code> then <code>select the clustering variables</code> of your choice, then click on <code>Run Analysis</code> and go to <code>HCPC</code> to generate Factor map, Chord diagram and Chord diagram - Cluster means which are downloadable in PNG, TIFF or PDF formats with interpretation and tables. The tables can be either copied or downloaded in <code>.xlsx</code> or <code>.csv</code> formats for use in reports or presentations.</p>
<div class="quarto-layout-panel">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<div id="fig-facmap" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Factor_map.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;18: <strong>Factor Map</strong></figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<div id="fig-chord" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Chord.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;19: <strong>Chord diagram</strong></figcaption>
</figure>
</div>
</div>
<div class="quarto-layout-cell" style="flex-basis: 33.3%;justify-content: center;">
<div id="fig-chordmean" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Means_Chord.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;20: <strong>Chord diagram - Cluster means</strong></figcaption>
</figure>
</div>
</div>
</div>
</div>
<p>In the <a href="#fig-facmap">Figure&nbsp;18</a> the Factor map displays the results of Hierarchical Clustering on Principal Components (HCPC), where observations are grouped into distinct clusters based on their similarity across all variables. The plot is constructed in a reduced two-dimensional space using the first two principal components (Dim1 and Dim2), which capture the maximum variance in the data while preserving the essential structure of the original multidimensional dataset. Each cluster is represented by a different color and enclosed in a convex hull (shaded polygon), making it easy to visually distinguish between groups. Observations within the same cluster share similar characteristics across the measured variables, while observations in different clusters exhibit distinct patterns or profiles. The percentages shown on each axis indicate how much of the total variance in the data is explained by that dimension - higher percentages mean that dimension captures more information about the differences between observations. The spatial separation between clusters reflects how different they are: clusters that are far apart have very different profiles, while clusters that are closer together are more similar. Overlapping regions suggest some ambiguity in cluster boundaries, where observations share characteristics with multiple groups. The position of each observation (data point label) within the plot is determined by its scores on the principal components, allowing you to see not only which cluster each observation belongs to but also how it relates to other observations within and across clusters. This visualization helps identify natural groupings in your data, understand the relationships between observations, and assess the quality of the clustering by examining how well-separated and cohesive the clusters appear in the reduced dimensional space</p>
<div id="fig-topvar" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Topvariables%20.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;21: <strong>Top variables</strong></figcaption>
</figure>
</div>
<p>In <a href="#fig-topvar">Figure&nbsp;21</a>, the table shows the top contributing variables for each cluster based on the v.test statistic from the HCPC analysis. For each cluster, the five variables with the highest absolute v.test values are displayed. ‚ÄòMean in category‚Äô and ‚Äòsd in category‚Äô show the standardized mean and standard deviation within the cluster, while ‚ÄòOverall mean‚Äô and ‚ÄòOverall sd‚Äô provide reference values across all data. The p.value indicates the statistical significance of the variable‚Äôs contribution. Variables with higher absolute v.test values and lower p.values are more important in defining the cluster.</p>
<p>In <a href="#fig-chord">Figure&nbsp;19</a>, the chord diagram visualizes the relationships between your original variables and the identified clusters from Hierarchical Clustering on Principal Components (HCPC). The outer ring shows two types of segments: your original dataset variables and the clusters (groups of similar observations). The ribbons connecting them represent the strength of association, with wider ribbons indicating that a variable is more characteristic or defining for that particular cluster. The width is determined by v.test statistics, which measure how strongly a variable distinguishes each cluster from others. By examining these connections, you can understand the profile of each cluster - which variables are most prominent in defining each group. Variables with thick ribbons to a cluster are key features of that group, while variables connected to multiple clusters play important roles across different groups. The diagram displays the most characteristic variables for each cluster with weights normalized within each cluster, allowing you to compare the relative importance of variables in defining cluster identities and understand what makes each group unique in your dataset.</p>
<div id="fig-pca" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ClusSum.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;22: <strong>PCA Summary Table</strong></figcaption>
</figure>
</div>
<p>In <a href="#fig-pca">Figure&nbsp;22</a>, the table summarizes the results of Principal Component Analysis (PCA), showing how much variance each principal component explains in the dataset. The eigenvalue indicates the amount of variance captured by each component, with larger values representing more important components. The percent column shows the proportion of total variance explained by each component, while the cumulative percent shows the running total across components. Components with eigenvalues greater than 1 are typically considered meaningful. This information helps determine how many components are needed to adequately represent the original data and forms the basis for subsequent clustering analysis.</p>
<div id="fig-clusqua" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="ClusQua.png" class="img-fluid figure-img" style="width:100.0%"></p>
<figcaption class="figure-caption">Figure&nbsp;23: <strong>Cluster quality indicators</strong></figcaption>
</figure>
</div>
<p>In <a href="#fig-clusqua">Figure&nbsp;23</a>, the table summarizes the variance in the dataset with respect to clustering. Total Sum of Squares (Total_SS) represents the overall variability in the data. Within-Cluster Sum of Squares (Within_SS) measures variability of observations inside each cluster. Between-Cluster Sum of Squares (Between_SS) quantifies variability between cluster centers. The Between/Total Ratio indicates the proportion of total variance explained by the differences between clusters. Higher ratios mean better separation between clusters.</p>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>